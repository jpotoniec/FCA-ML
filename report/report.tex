\documentclass{llncs}
\usepackage[utf8]{inputenc}
\usepackage[OT4]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage[percent]{overpic}
\usepackage{fp}

\usepackage{hyperref}

\newcommand{\pc}{\ensuremath\mathcal{K}}
\newcommand{\soi}{\ensuremath\mathcal{L}}
\newcommand{\next}{\ensuremath\mathcal{N}}
\newcommand{\ont}{\ensuremath\mathcal{O}}
\newcommand{\tbox}{\ensuremath\mathcal{T}}
\newcommand{\abox}{\ensuremath\mathcal{A}}
\newcommand{\ind}{\ensuremath\mathcal{I}}
\newcommand{\mapping}{\mathcal{M}}
\DeclareMathOperator{\POD}{pod}
\newcommand{\comment}[1]{\emph{#1}}

%overpic is based on picture, which supports calc somehow, which has \widthof and \heightof
\newcommand{\pmark}[3]{
	\FPeval\textx{#1-.75}
	\FPeval\texty{#2-1}
	\put (#1,#2) {\circle{3}} 
	\put (\textx,\texty) {#3}
	}

\title{Integration of Machine Learning with Formal Concept Analysis for Ontology Refinement}
\author{JÄ™drzej Potoniec}
\institute{Poznan University of Technology}
\begin{document}
\maketitle
\begin{abstract}
\end{abstract}

\section{Introduction}


\section{Attribute exploration in formal concept analysis}

Following description of formal concept analysis and attribute exploration algorithm are based on \cite{baader2007completing}.

Let $M$ be finite set of attributes 
$M=\{m_1,m_2,\ldots,m_n\}$ with fixed linear order on it such that
$m_1<m_2<\ldots<m_n$. 

\emph{Partial object description (pod)} is a tuple
$(A,S)$ such that $A,S\subseteq M$. If $A\cup
S=M$, this tuple is
\emph{full object description (fod)}. Object described by given pod
has all attributes of $A$ and none of $S$. It is unknown if the object has or
has not some attributes, namely those in set $M\backslash (A\cup S)$.

Set of pods is called \emph{partial context} and further is be denoted by $\pc$.
Set of fods is called \emph{full context}. 

\emph{Implications} considered in attribute exploration algorithm are of form
$L\rightarrow R$, where $L,R\subseteq M$. Implication is \emph{refuted by pod}
$(A,S)$ if and only if $A\subseteq L \land S\cap R\neq\emptyset$. In other words, pod
refutes implication if it fullifies its left-hand side (that is has all
attributes mentioned in left-hand side) and does not have some of the attributes in right-hand side.
Implication is \emph{refuted by partial context} if it is refuted by at least
one pod from this partial context.


\begin{definition}[implicational closure]
Let $\soi$ be a set of implications. $\soi(P)\subseteq M$ is an \emph{implicational closure} of a set of attributes $P\subseteq M$ if and only if:
\begin{itemize}
\item $P\subseteq\soi(P)$
\item If $L\to R\in\soi$ and $L\subseteq \soi(P)$, then $R\subseteq\soi(P)$.
\item $\soi(P)$ is smallest set holding both above conditions.
\end{itemize}
If $\soi(P)=P$, then $P$ is called $\soi$-closed.
\end{definition}


\begin{definition}[lectic order]
For any two sets $P,Q\subseteq M$ and for any $i=1,2,\ldots,n$
\[P<_i Q \equiv \left(m_i\in Q\backslash P \land P\cap \{m_1,\ldots,m_{i-1}\}=Q\cap \{m_1,\ldots,m_{i-1}\} \right) \]

\emph{Lectic order $<$} is union of orders $<_i$: $<=<_1 \cup <_2 \cup \ldots \cup <_n$.
\end{definition}
In other words $P$ is before $Q$ in order $<_i$ if they both contain exactly the same attributes up to an attribute $m_{i-1}$ and an attribute $m_i$ belongs only to the set $Q$ and not to the set $P$.

\begin{definition}
For a shorthand lets define $f(P,i)=\soi((P\cap \{m_1,\ldots,m_{i-1}\})\cup\{m_i\})$ for every $\soi$-closed $P\subseteq M$ and every $i=1,2,\ldots,n$. \marginpar{Why closed if later it is used on non-closed sets? Seems that \cite{ganter99} p. 85 does not have it.}
$\next(P)$ is next $\soi$-closed set following $P$ w.r.t. the lettic order $<$: 
\[\next(P)=f(P,j) \qquad j=\max\{1\leq i\leq n: P<_i f(P,i)\} \]
\end{definition}

Let $\ont=(\tbox,\abox)$ be a consistent DL-ontology. Let $M$ be a linearly-ordered
set of concept expressions in DL, serving as attributes for partial object
descriptions. Let $\ind_\abox$ be a set of individuals in $\abox$.
$\POD_\ont(a,M)$ is partial object description induced by an individual
$a\in\ind_\abox$:
\[ \POD_\ont(a,M)=\left(\{C\in M: \ont\models C(a)\}, \{C\in M: \ont\models \lnot C(a)\}\right) \]
$\pc_{\ont,M}$ is partial context induced by the ontology w.r.t. set of attributes $M$:
\[ \pc_{\ont,M}=\{\POD_\ont(a,M): a\in\ind_\abox \} \]

\begin{definition}
Let $\pc$ be a partial context and let $P\subseteq M$. 
$\pc(P)$ defined as follows is the largest subset of $M$ such that implication $P\to \pc(P)$ is not refuted by $\pc$.
\[ \pc(P)=M\backslash \bigcup_{\substack{(A,S)\in\pc\\P\subseteq A}} S \]
\end{definition}

\begin{definition}[Algorithm of attribute exploration for DL KBs]
Input: $\ont, M$. Output: altered $\ont$.
\begin{enumerate}
\item $\soi\leftarrow \emptyset, P\leftarrow \emptyset$
\item\label{algdl:while} If $P=M$, then stop. \comment{All attributes have been considered.}
\item \comment{Considering implication $P\to\pc_{\ont,M}(P)$.}
\item If $P=\pc_{\ont,M}(P)$, then go to \ref{algdl:next}. \comment{Implication is trivial, because premises and conclusions are the same.}
\item If $\ont\models \bigsqcap P \sqsubseteq \bigsqcap \pc_{\ont,M}(P)$, then go to \ref{algdl:store}. \comment{Implication follows from $\ont$.}
\item Ask expert if implication is correct. If it is, go to \ref{algdl:store}.
\item Request expert to extend $\abox$ such that implication is refuted, but all implications in $\soi$ stay currect. Go to \ref{algdl:while}.
\item \label{algdl:store} $\soi\leftarrow \soi\cup \{P\to\pc_{\ont,M}(P)\backslash P\}$ \comment{Remember implication as correct.}
\item $\tbox\leftarrow\tbox\cup\{\bigsqcap P \sqsubseteq \bigsqcap \pc_{\ont,M}(P)\}$ \comment{Alter the ontology with newly discovered subsumption.}
%\item $P\leftarrow \soi(P)$ \comment{Close $P$, as $\next(\cdot)$ is defined only for $\soi$-closed sets. This is not present in \cite{baader2007completing} and aparently for a reason, because it is not correct.}
\item \label{algdl:next} $P\leftarrow \next(P)$ \comment{Go to the next set of premises.}
\item Go to \ref{algdl:while}.
\end{enumerate}
\end{definition}

\begin{example}
\begin{gather*}
\ont=(\tbox,\abox) \\
\tbox=\{MoT, Train, Car, Dog, Train\subseteq MoT\} \\
\abox=\{Car(c1), MoT(c2), Car(c2), \lnot Train(c2), MoT(t1), Dog(max), Dog(jack)\} \\
M=\{MoT, Train, Car, Dog\}
\end{gather*}
$MoT$ stands for means of transportation.

Induced partial context $K_{\ont,M}$ is presented in a form of table in Table~\ref{tab:ex1:pc_input}.
Every row represents single pod, \emph{plus} means that given object has given attribute, \emph{minus} means that given object does not have given attribute, empty cell means that it is unknown if object has given attribute.

Below brief sketch of possible run of the algorithm is presented for the context $K_{\ont,M}$.
\begin{enumerate}
\item $\emptyset \to \{MoT , Car , Dog\}$\\
Rejected with counterexample $\lnot Dog(c1)$.
\item $\emptyset \to \{MoT , Car\}$\\
Rejected with counterexample $\lnot MoT(max), \lnot Car(max)$.
\item $\{Dog\} \to \{Train\}$\\
Rejected with counterexample $\lnot Train(max)$.
\item $\{Car\} \to \{MoT\}$\\
Accepted.
\item $\{Train\} \to \{MoT, Car, Dog\}$\\
Rejected with counterexample $Train(t1), \lnot Car(t1), \lnot Dog(t1)$.
\item $\{Train\} \to \{MoT\}$\\
Follows from $\ont$.
\item $\{MoT, Dog\} \to \{Train, Car\}$\\
Accepted.
\item $\{MoT, Train, Car\} \to \{Dog\}$\\
Rejected with new counterexample\footnote{\url{http://www.tabor.com.pl/wp-content/gallery/ciagnik-szynowo-drogowy/ciagnik.jpg}} $Train(csd), Car(csd), \lnot Dog(csd)$.
\end{enumerate}

Finally, two new subsumptions have been discovered: $Car \sqsubseteq MoT$ and $MoT \sqcap Dog \sqsubseteq Train \sqcap Car$. Obtained partial context is presented in Table \ref{tab:ex1:pc_output}.

\end{example}

\begin{table}
\begin{minipage}{.49\textwidth}
\caption{Partial context $K_{\ont,M}$ induced by the example ontlogy $\ont$.\label{tab:ex1:pc_input}}
\begin{tabular}{|l||c|c|c|c|}
\hline
individual & MoT & Train & Car & Dog \\
\hline
\hline
c1 & & & + & \\
\hline
c2 & + & -- & + & \\
\hline
t1 & + & & & \\
\hline
max & && & +  \\
\hline
jack & && & + \\
\hline
\end{tabular}
\end{minipage}
\begin{minipage}{.49\textwidth}
\caption{Partial context obtained from exemplar running of the algorithm.\label{tab:ex1:pc_output}}
\begin{tabular}{|l||c|c|c|c|}
\hline
individual & MoT & Train & Car & Dog \\
\hline
\hline
c1 & + & & + & --\\
\hline
c2 & + & -- & + & \\
\hline
t1 & + & + & -- & -- \\
\hline
max & -- & -- & --  & +  \\
\hline
jack & && & + \\
\hline
{csd} & {+} & {+} & {+} & {-}  \\
\hline
\end{tabular}
\end{minipage}
\end{table}


\section{Attribute exploration with special subset}

We consider users interested in extending knowledge base w.r.t. some set of
attributes $N\subseteq M$. It is not enough for them to set $M$ and $N$ equal, as
this would stop them from finding implications with attributes from
$M\backslash N$.

\begin{definition}[interesting implication]
Implication $L\to R$ is \emph{interesting w.r.t. set $N$ of attributes} if $L\cap N\neq\emptyset \lor R\subseteq N$. In other words, implication is interesting if one of the following happens:
\begin{itemize}
\item premises contains at least one interesting attribute;
\item conclusions consists of only interesting attributes.
\end{itemize}
\end{definition}

Any implication $L\to R$ can be transformed into an interesting one $L\to R'$ along the following procedure:
\begin{enumerate}
\item If $L\cap N\neq\emptyset$, then $R'\leftarrow R$. Implication was already interesting.
\item Otherwise, limit conclusions only to the interesting ones: $R'\leftarrow R\cap N$.
\end{enumerate}

\begin{definition}[set of user-friendly implications]
Implication $L\to R$ induces set of user-friendly implications $I(L\to R)$:
\[ I(L\to R)=\{L\to\{x\}: x\in R\} \]
Implications in this set have single attribute in conclusion. This way users can decide more easily if implication is correct and automatic generation of counter-examples is easier.
\end{definition}

\begin{proposition}
Presenting to the user set of implications $I(L\to R)$ and the implication $L\to R$ is equivalent w.r.t. the ground truth. 
\end{proposition}

\begin{proof}
Implication $L\to R$ is corresponds to the following DL subsumption: $\bigsqcap L \sqsubseteq \bigsqcap R$, which is equivalent to the following set of subsumptions:
\[ \bigsqcap L \sqsubseteq r \quad \forall r\in R \]
Every of these subsumptions corresponds to an implication $L\to\{r\}$ and whole
set of subsumptions to the set $I(L\to R)$. If all of these implications are
accepted, whole set of subsumptions is added to the knowledge base $\ont$ and
as consequence $\ont\models \bigsqcap L \sqsubseteq \bigsqcap R$. On the other
hand, if any of implications from $L\to\{r\}$ is rejected, then in $\ont$
exists counterexample $a$ such that $\bigsqcap L(a) \sqcap \lnot r(a)$. $a$ is also counterexample for implication $L\to R$, as $\{\lnot r(a)\} \models \lnot\bigsqcap R(a)$ for any $r\in R$.

One may notice that in general $\lnot R(a)\not\models \lnot r(a)$ for any 
$r\in R$, as the knowledge base may contains statements like $(\lnot r_1 \sqcup
\lnot r_2)(a)$. This is not the case as long the user can alter knowledge base
only through partial context editing and not by adding arbitrary DL
expressions.  
\end{proof}


%Because $A\subseteq B \implies \pc(B)\subseteq\pc(A)$, so $\pc({x})$ is the biggest subset of attributes 

\begin{definition}[User-friendly algorithm of attribute exploration for DL KBs]
Input: $\ont, M$. Output: altered $\ont$.
\begin{enumerate}
\item $\soi\leftarrow \emptyset, P\leftarrow \emptyset$
\item\label{algint:while} If $P=M$, then stop. \comment{All attributes have been considered.}
\item \comment{Considering implication $P\to\pc_{\ont,M}(P)$.}
\item $goToNext\leftarrow true$ \comment{Helper variable to decide if $P$ should be replaced by new set of premises.}
\item If $P=\pc_{\ont,M}(P)$, then go to \ref{algint:next}. \comment{Implication is trivial, because premises and conclusions are the same.}
\item For every implication $P\to \{r\} \in I(P\to\pc_{\ont,M}(P)\backslash P)$ do the following: \comment{Iterating over all interesting implications}
\begin{enumerate}
\item If implication $P\to \{r\}$ is already refuted by $\pc_{\ont,M}$, go to \ref{algint:next_impl}.
\item If $\ont\models \bigsqcap P \sqsubseteq r$, then go to \ref{algint:store}.
\item Ask expert if implication is correct. If it is, go to \ref{algint:store}.
\item Request expert to extend $\abox$ such that implication is refuted, but all implications in $\soi$ stay currect.
\item Set $goToNext\leftarrow false$ and go to \ref{algint:next_impl}. \comment{Forbid going to next set of premises as at least one implication was rejected.}
\item \label{algint:store} $\soi\leftarrow \soi\cup \{P\to\{r\}\}$ \comment{Remember implication as correct.}
\item $\tbox\leftarrow\tbox\cup\{\bigsqcap P \sqsubseteq r\}$ \comment{Alter the ontology with newly discovered subsumption.}
\item \label{algint:next_impl} Go to next implication.
\end{enumerate}
\item \label{algint:next} If $goToNext$ is $true$, set $P\leftarrow \next(P)$ \comment{Go to the next set of premises.}
\item Go to \ref{algint:while}.
\end{enumerate}
\end{definition}



\section{Preparing partial context}

\begin{definition}[Query pattern]
Query pattern is a \emph{graph pattern} as defined in \cite{sparql11-ql} or any equivalent concept. Lets denote by $\mathbb{Q}$ set of all valid query patterns and by $\mathbb{Q}(V)\subset\mathbb{Q}$ set of all these patterns containing variable $V$.
\end{definition}

\begin{definition}[Linked Data mapping]
\emph{Linked Data mapping} is a triple $(E,V,\mapping)$, where:
\begin{description}
\item[$E$] is an identifier (address) of query answering service;
\item[$V$] is distincted variable in queries;
\item[$\mapping$] is a partial function from $M$ to $\mathbb{Q}(V)$ associating attributes with query patterns.
\end{description}
\end{definition}

\begin{example}[Mapping for learning about Middle-earth from DBpedia]
Consider the following mapping:
\begin{description}
\item[$E$] \url{http://dbpedia.org/sparql}
\item[$V$] \texttt{?x}
\item[$\mapping$] ~\\ \begin{tabular}{p{.25\textwidth}p{.75\textwidth}}
Attribute & Pattern \\
\hline
Man & \texttt{?x dbp-prop:characterRace dbpedia:Man\_\%28Middle-earth\%29} \\
Noldor & \texttt{?x dbp-prop:characterCulture dbpedia:Noldor} \\
Spider-Demon & \texttt{?x dcterms:subject dbpedia:Category\%3AFictional\_demons, dbpedia:Category\%3AFictional\_spiders, dbpedia:Category\%3AMiddle-earth\_characters}
\end{tabular}
\end{description}
\end{example}

To enable attribute exploration with ontologies where $\abox=\emptyset$, the
following algorithm is used. $\abox$ obtained this way is not meant to be used
only as a seed for attribute exploration, not as part of final ontology. This
algorithm should provide witness for every mapped attribute that in fact this
attribute (more precisely: DL-concept related with this attribute) is
satisfiable.  
\begin{definition}[Algorithm for population of $\abox$]
\marginpar{Extend to multiple mappings.}
Input: mapping $(E,V,\mapping)$. Output: $\abox$.

Lets denote by $M_\mapping\subseteq M$ set of all these attributes $A$ for which $\mapping(A)$ is defined.
For every $A\in M_\mapping$ do the following:
\begin{enumerate}
\item Obtain witness of attribute $A$, by posing to the service $E$ query equivalent to the following SPARQL query template:
\texttt{SELECT $V$ WHERE \{ $\mapping(A)$ \} LIMIT 1}. Use obtained name $a$ as name of an individual in $\abox$: 
\[ \abox \leftarrow \abox \cup \{ A(a) \} \]
\item For every $A'\in M_\mapping\backslash\{A\}$ pose to the service $E$ query equivalent to the following SPARQL query template:
\texttt{ASK WHERE \{ $\mapping(A')$ \} BINDINGS $V$ \{($a$)\}}. If the answer is positive, alter $\abox$:
\[ \abox \leftarrow \abox \cup \{ A'(a) \} \] Otherwise ignore result, as it
is meaningless: it may mean that remote knowledge base is incomplete (and in
fact $A'(a)$), that knowledge base is complete but holds close-world assumption
(and in fact $\lnot A'(a)$) or that it is unknown if $A'(a)$ or $\lnot A'(a)$.
\end{enumerate}
\end{definition}

If mappings and/or remote knowledge base are errorneus, context obtained from
this $\abox$ requires manual correction, because otherwise attribute
exploration algorithm will be conformant with the principle \emph{garbage in,
garbage out}.


\section{Integrating machine learning algorithms into attribute exploration}

Algorithm of attribute exploration requires good amout of work from users in answering if implications are correct or wrong. One can observe that many of considered implications are of similar structure. It would be desirable if an algorithm would be able to learn from user decisions and gradually help him/her during the process answering more and more questions. Of course, it may happen that answer given by the algorithm is wrong. In this case it is far better to reject correct implication (as user just does not earn additional knowledge) than to accept a wrong one (because it creates cost for the user, as it requires manual detection and correction).

In classic approach for attribute exploration in DL KBs this would be hard to achieve, because of lack of counterexamples for rejected implications. If only implications with single attribute in conclusion are considered, counterexamples can be generated automatically. Moreover, it does not alter the properties of knowledge base as there is open-world assumption and no unique names assumption. For implication $P\to\{r\}$, new name $a$ is generated and $\abox$ is altered with the following expressions:
\begin{itemize}
\item $p(a)$ for every $p\in P$;
\item $\lnot r(a)$.
\end{itemize}

Task of deciding if implication is correct or wrong is represented as ternary classification task. Every implication is classified to one of the following classes:
\begin{description}
\item[correct] implication is remembered as correct and next implication is generated;
\item[wrong] new counterexample is generated, as described above;
\item[undecided] user is asked if implication is correct or wrong. 
\end{description}
This task can be seen as a form of active learning: user is asked to label
(i.e. give definite answer if implication should be accepted or rejected) these
implications, which are too hard for machine learning algorithm to classify.

\subsection{Implication features}

To use implication as an example in classification task, implication must be
transformed into a feature vector. Used features are derrived from these used
in association rules mining and in pattern mining. Let $L\to R$ be a considered
implication.

\paragraph{Context-based features} Let $\ont=(\tbox,\abox)$ be a considered
ontology. We use some measures intended for
associacion rule mining, as described in \cite{lebras}. For sake of claricity,
assume that for any class $C$, $\left|C\right|$ is number individuals known to belong to class $C$, that is
\[ \left|C\right|=\left|\{a\colon \ont\models C(a)\}\right|\]

Following four values can be defined:
\begin{itemize}
\item relative number of individuals known to support implication premises and known not to support implication conclusions
\[x_{owa}=\frac{\left|\bigsqcap L \sqcap \lnot\bigsqcap R\right|}{\left|\top\right|}\]
\item relative number of individuals known to support implication, but not known to support implication conclusions
\[x_{cwa}=\frac{\left|\bigsqcap L\right|-\left|\bigsqcap L \sqcap \bigsqcap R\right|}{\left|\top\right|} \]
\item relative support for implication premises
\[y=\frac{\left|\bigsqcap L\right|}{\left|\top\right|} \]
\item relative support for implication conclusions
\[z=\frac{\left|\bigsqcap R\right|}{\left|\top\right|} \]
\end{itemize}

With values $x, y, z$ defined above, the following measures (features) can be defined:
\begin{description}
\item[coverage] $y$
\item[prevalence] $z$ 
\item[support (CWA)] $y-x_{cwa}$
\item[support (OWA)] $y-x_{owa}$
\item[recall/local support (CWA)] $\frac{y-x_{cwa}}{z}$
\item[recall/local support (OWA)] $\frac{y-x_{owa}}{z}$
\item[lift (CWA)]  $\frac{y-x_{cwa}}{yz}$
\item[lift (OWA)] $\frac{y-x_{owa}}{yz}$
\end{description}
Although it may seem complex at first glance, this approach with intermediate variables helps in efficient calculation of above features.

\paragraph{Shape-based features} On the structural side of the implication attributes based on number of attributes in implication or any of its parts can be defined. More specifically, one can consider following attributes:
\begin{description}
\item[absolute premises size] $\left|L\right|$
\item[relative premises size] $\frac{\left|L\right|}{\left|M\right|}$
\item[absolute conclusions size] $\left|R\right|$
\item[relative conclusions size] $\frac{\left|R\right|}{\left|M\right|}$
\item[absolute implication size] $\left|L\right|+\left|R\right|$
\item[relative implication size] $\frac{\left|L\right|+\left|R\right|}{\left|M\right|}$
\end{description}
In case of system considering only user-friendly implications, only first two attributes makes sense, because other are constant for all implications.

\paragraph{Endpoint calculator}
Given is a Linked Data mapping $(E,V,\mapping)$ and a set of attributes $X$. Lets denote by $M_\mapping\subseteq M$ set of all these attributes $A$ for which $\mapping(A)$ is defined.
\emph{Remote support} $r(X)$ can be computed along the following procedure:
\begin{enumerate}
\item If $X\not\subseteq M_\mapping$, then set $r(X)$ to an invalid value and stop.
\item Build query pattern $Q$ joining with conjunction all patterns from a set $\mapping(X)$.
\item Pose to the service $E$ query equivalent to the following SPARQL query template:
\texttt{SELECT COUNT(DISTINCT $V$)) WHERE \{ $Q$ \}}.
\item Assign retrieved value to $r(X)$. If some error occured, set $r(X)$ to invalid value.
\end{enumerate}
Invalid value should be understand as missing value in machine learning steps.

Having remote support, one can compute following features:
\begin{description}
\item[absolute remote support of premises] $r(L)$
\item[absolute remote support of conclusions] $r(R)$
\item[absolute remote support of premises and conclusions] $r(L\cup R)$
\item[relative remote support of premises] $\frac{r(L)}{r(L\cup R)}$
\item[relative remote support of conclusions] $\frac{r(R)}{r(L\cup R)}$
\end{description}

\subsection{ML algorithms}

Classification of implications can be seen as ternary classification from the
point of view of machine learning algorithm, but from user's point of view it
is binary classification. More precisely, user must decide if implication is
\emph{correct} or \emph{wrong}, but algorithm has third class: \emph{I do not
know}. Because of this imbalance, this task can not be solved as classical
classification. Instead, approaches derrived from active learning are required.

Instead of crisp decision if to accept or reject implication, algorithm should
generate probability of acceptance. If this probability is high enough,
implication is decided to be accepted. If it is low enough, implication is
rejected and counterexample is generated. Otherwise, user is asked about
considered implication. 

One should note that not every classifier generates
reasonable probabilities. For example, rule-based or tree-based systems like
\cite{Cohen1995} were not designed for that purpose. Some of implementations
(e.g. in Weka \cite{weka}) can provide probabilities, but they are
rather fired rule's confidence, not real probability.

Problem of generating probabilities can be also seen as a regression problem,
that is learning a function which maps features (indepented variables) to a
continous value (dependent variable) instead of finite set of classes
\cite{regression}. This approach is used e.g. in logistic regression, where
output of multiple weak classifiers such as decision stumps
\cite{decision-stumps} is combined with linear regression to obtain accurate
probability estimation \cite{Friedman1998,friedman2000special}.

%highly imbalanced

Another aspect which should be considered is high possibility of imbalanced 
distribution of classes. For example, if lots of attributes are considered by
the expert to be disjoint, many implications with unsatisfiable (but not from
point of view of background knowledge) will be generated and all those
implications will be accepted as valid. This can easily lead to having 10 times
more positive examples than negative ones. Moreover, the expert can provide
small counterexamples thus making algorihtm generate subseqent
implications which are to be rejected or provide broader ones, which forbid
generation of whole group of implications. For example, for implication
$\{Dog\}\to\{MoT,Train,Car\}$ one can give small counterexample $\lnot
Car(burek)$ or transform burek's partial object description into full object
description, by stating that burek is neither $MoT$, $Train$ nor $Car$.

With imbalanced distribuion comes another problem of cost-sensitive learning.
Due to the nature of attribute exploration algorithm errors of commision (that
is acceptance of
invalid implication) are worser than errors of omission (rejection of valid
implication). That is because commision leads to wrong subsumptions in
knowledge base and omission leads just to missing subsumptions. 

Following previous example, lets consider
implication $\emptyset\to\{Dog\}$: should it be accepted, every individual in
the knowledge base would be stated to be a dog, which is clearly wrong. On the
other hand, the only cost of rejecting implication is $\{Car\}\to\{MoT\}$ is
not gaining knowledge and introduction of invalid counterexample.

Problem of cost-sensitive learning is usually considered in context of medical
diagnosis or treatments detection, where it is better to state that health
patient has caner or that an innocent person carries a bomb to a plane than to
miss ill person or a terrorist \cite{ting1998inducing,cost-sensitve_learning}.

\section{Experimental evaluation}

Every newly proposed algorithm requires careful experimental validation to
prove its usefulness. Below we present our experimental environment and
describe case study on learning races and cultures of Tolkien's Middle-Earth.

\subsection{Implementation}

For purpose of experimental evaluation, previously described algorithms were implemented in as a stand-alone Java application. There are four tabs which separate different functionalities:
\begin{description}
\item[Setup] tab presented in Figure \ref{fig:setup}. Attributes used in partial context, background knowledge and classifier are configured there.
\item[FCA] tab presented in Figures \ref{fig:fca1} and \ref{fig:fca2}. Here interaction with attribute exploration algorithm is possible.
\item[Classifier] tab presented in Figure \ref{fig:classifier}. User can see here performance of classifier, learning examples and implications considered so far.
\item[Mappings] tab presented in Figure \ref{fig:mappings}, where Linked Data mapping can be specified.
\end{description}

\begin{figure}
\begin{overpic}[width=\textwidth,trim=0 5cm 0 0,clip]{screenshots/setup.png}
\pmark{55}{52}{1}
\pmark{95}{52}{2}
\pmark{10}{35}{3}
\pmark{60}{37}{4}
\pmark{25}{15}{5}
\pmark{60}{15}{6}
\pmark{95}{15}{7}
\end{overpic}
\caption{Setup tab: (1)  selection of features, (2)  files with background
knowledge, (3)  reasoner to use, (4)  classifier configuration, (5)  all
possible attributes, (6)  attributes to be used, (7)  interesting
attributes.\label{fig:setup}}
\end{figure}

\begin{figure}
\begin{overpic}[width=\textwidth,trim=0 9cm 0 0,clip]{screenshots/fca1.png}
\pmark{10}{47}{1}
\pmark{20}{40}{2}
\pmark{40}{32}{3}
\pmark{50}{45}{4}
\pmark{50}{37}{5}
\pmark{90}{40}{6}
\pmark{40}{20}{7}
\end{overpic}
\caption{FCA tab right after attribute exploration was started: (1)  current
implication and possible decisions, (2)  status of classifier, (3)  search box
for findings individuals by name, (4)  buttons for extending partial context
with new individuals, (5)  button to export already discovered
implications to file, (6)  features of current implication, (7)
partial context.\label{fig:fca1}}
\end{figure}

\begin{figure}
\begin{overpic}[width=\textwidth,trim=0 9cm 0 0,clip]{screenshots/fca2.png}
\pmark{10}{47}{1}
\pmark{20}{40}{2}
\pmark{40}{20}{3}
\end{overpic}
\caption{FCA tab during attribute exploration: (1)  an answer \emph{reject} is
suggested by a classifier, (2)  classifier is already working and its textual
representation is displayed, (3)  partial context was altered and new
individuals were added.\label{fig:fca2}} 
\end{figure}

\begin{figure}
\begin{overpic}[width=\textwidth,trim=0 9cm 0 0,clip]{screenshots/classifier.png}
\pmark{20}{40}{1}
\pmark{60}{40}{2}
\pmark{11.5}{31}{3}
\pmark{41}{10}{4}
\end{overpic}
\caption{Classifier tab: (1)  confusion matrix recording classifier vs user
decisions, (2)  all implications presented so far with probability of
acceptance and decision made, (3)  buttons for saving and loading learning
examples, (4)  learning examples, that is implications transformed to
features vectors and labelled with correct decision.\label{fig:classifier}}
\end{figure}

\begin{figure}
\begin{overpic}[width=\textwidth,trim=0 9cm 0 0,clip]{screenshots/mappings.png}
\pmark{9}{48.5}{1}
\pmark{40}{46}{2}
\pmark{40}{40}{3}
\pmark{40}{20}{4}
\end{overpic}
\caption{Mappings tab: (1) buttons for loading and saving mappings, (2) SPARQL endpoint address, (3) prefixes used in mappings, (4) mapping from attribute name to SPARQL graph pattern.\label{fig:mappings}}
\end{figure}

The application uses OWLAPI\footnote{\url{http://owlapi.sourceforge.net}}
\cite{owlapi} to process background knowledge.  OWLAPI also enables use of
different reasoners. Currently available are
Pellet\footnote{\url{http://clarkparsia.com/pellet/}}
\cite{pellet}, Hermit\footnote{\url{http://hermit-reasoner.com}} \cite{hermit}
and JFact\footnote{\url{http://jfact.sourceforge.net/}} (Fact++ for Java)
\cite{fact++}.

Attribute exploration algorithm has been implemented from scrath. We are aware
of OntoComP\footnote{\url{http://ontocomp.googlecode.com/}} \cite{ontocomp},
Protege plugin for attribute exploration and its
FCAlib\footnote{\url{http://fcalib.googlecode.com}}, but decided that proposed
changes are too complex to be easily incorporated into FCAlib.

For classification excellent
Weka\footnote{\url{http://www.cs.waikato.ac.nz/ml/weka/}} library has been used
\cite{weka}. This library provides implementations of various algorithms for
solving all main tasks of machine learning, such as classification or
clustering. Moreover, Weka provides useful additional components, such as
generic file format for storing learning examples in files, with appropriate
classes to load and save them.

\subsection{Case study: learning about Middle-Earth}

We did preliminary experimental evaluation on small ontology about spieces,
races and cultures in J.R.R. Tolkien's Middle-Earth. Vocabulary has been
gathered from a family tree created by \emph{Lord of the Rings
Project}\footnote{\url{http://lotrproject.com/}}. This vocabulary was further
refined to form simple ontology by adding some subsumption relation. This was
done very roughly to simulate casual user behaviour, who knows something, but
not everything about relationships in the ontology.

In addition FOAF
ontology\footnote{\url{http://xmlns.com/foaf/spec/}} was used as a top-level
ontology and \texttt{foaf:Agent} was made a superclass of every class in
created onology.

Further mappings between some of defined concepts and Linked Data have been
created. More specifically, DBpedia 3.9 have been used and mappings are
presented in Table \ref{tab:lotr_mapping}. It should be noted
that those mappings are based on raw data rather than on DBpedia ontology, because it just does not cover these topics \cite{dbpedia}. 

Proposed mappings are on purpose imperfect. For example, \texttt{Person} is
mapped to every character from "The Silmarillion", "The Lord of the Rings" or
"The Hobbit, or There and Back Again" known to DBpedia. Shelob is also
character there (namely in "The Two Towers"), but surely giant spiders should
not be classified as persons. This reflects real-world scenarios, where Linked
Data may not correspond perfectly with considered ontology or they may be just
erroneous.

To avoid unnecessary load on remote SPARQL endpoint, local copy of DBpedia have
been set up with OWLIM\footnote{\url{http://owlim.ontotext.com/}} version 5.3
\cite{owlim}. In the begining experiments were made with remote endpoint
provided by FactForge\footnote{\url{http://factforge.net/}} \cite{factforge} and this
proved that proposed method is conservative enough to be run on a remote SPARQL
endpoint.

\emph{Current results seem promising, but we still lack of their analysis and thus they are hard to describe or comment.}

\begin{table}
\caption{Mapping from attribute name to SPARQL graph pattern. Prefix \texttt{dbp-prop:} stands for \url{http://dbpedia.org/property/}, \texttt{dbpedia:} for \url{http://dbpedia.org/resource/} and \texttt{dcterms:} for \url{http://purl.org/dc/terms/}.
\label{tab:lotr_mapping}}
\begin{tabular}{p{.15\textwidth}|p{.85\textwidth}}
 attribute & SPARQL graph pattern \\
 \hline
Ainur & 
\texttt{\{\{?x dbp-prop:characterRace dbpedia:Ainur\_\%28Middle-earth\%29\} UNION \{?x dbp-prop:characterRace dbpedia:Ainu\_\%28Middle-earth\%29 \}\}}
 \\  
Man & 
\texttt{?x dbp-prop:characterRace dbpedia:Man\_\%28Middle-earth\%29}
 \\  
Dunedain & 
\texttt{?x dbp-prop:characterCulture dbpedia:D\%FAnedain}
 \\  
Dwarf & 
\texttt{?x dbp-prop:characterRace dbpedia:Dwarf\_\%28Middle-earth\%29}
 \\  
Elf & 
\texttt{?x dbp-prop:characterRace dbpedia:Elf\_\%28Middle-earth\%29}
 \\  
Ent & 
\texttt{?x dbp-prop:characterRace dbpedia:Ent}
 \\  
Half-elf & 
\texttt{?x dbp-prop:characterRace dbpedia:Half-elven}
 \\  
Hobbit & 
\texttt{?x dbp-prop:characterRace dbpedia:Hobbit}
 \\  
Maiar & 
\texttt{?x dbp-prop:characterRace dbpedia:Maia\_\%28Middle-earth\%29}
 \\  
Noldor & 
\texttt{?x dbp-prop:characterCulture dbpedia:Noldor}
 \\  
Numenorean & 
\texttt{?x dbp-prop:characterCulture dbpedia:N\%FAmenor}
 \\  
Rohir & 
\texttt{?x dcterms:subject dbpedia:Category\%3AMiddle-earth\_Rohirrim}
 \\  
Sindar & 
\texttt{?x dbp-prop:characterCulture dbpedia:Sindar}
 \\  
Spider-Demon & 
\texttt{?x dcterms:subject dbpedia:Category\%3AFictional\_demons, dbpedia:Category\%3AFictional\_spiders, dbpedia:Category\%3AMiddle-earth\_characters}
 \\  
Teleri & 
\texttt{?x dbp-prop:characterCulture dbpedia:Teleri}
 \\  
Wolfhound & 
\texttt{?x dbp-prop:characterRace "Wolf"@en}
 \\  
Person & 
\texttt{\{\{?x dcterms:subject dbpedia:Category\%3ACharacters\_in\_The\_Silmarillion\}   UNION   \{?x dcterms:subject dbpedia:Category\%3ACharacters\_in\_The\_Lord\_of\_the\_Rings\}  UNION   \{?x dcterms:subject dbpedia:Category\%3ACharacters\_in\_The\_Hobbit\}  \}}\\
\end{tabular}
\end{table}

\bibliographystyle{plain}
\bibliography{report}

\end{document}
